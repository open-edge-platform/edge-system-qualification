# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

name: "profile.qualification.ai-edge-system"
description: "AI Edge System qualification"
version: "1.0.0"
params:
  labels:
    profile_display_name: "AI Edge System"
    group: "ai-edge-system"
    type: "qualification"
    display_reference: true
    kpi_enabled: true
  tiers:
    - entry
    - mainstream
    - efficiency_optimized
    # Xeon based specific tier
    - scalable_performance
    # dGPU based specific tiers
    - scalable_ai_graphics_media
    - scalable_ai_graphics_media_10gb
    - scalable_ai_graphics_media_24gb
    - scalable_ai_graphics_media_52gb
    - scalable_ai_graphics_media_hetero
    - scalable_ai_graphics_media_hetero_10gb
    - scalable_ai_graphics_media_hetero_24gb
    - scalable_ai_graphics_media_hetero_52gb
  requirements:
    memory_min_gb: 8.0
    os_type:
      - "linux"
    docker_required: true
  # Vision AI global params
  assets:
    - id: "yolo11n"
      type: "model"
      source: "ultralytics"
      precision: "int8"
      format: "pt"
      export_args:
        dynamic: true
        half: true
    - id: "video_6891009"
      type: "video"
      name: "6891009-apple_1080p15.mp4"
      url: "https://www.pexels.com/download/video/6891009"
      sha256: "b30010389562c03a15dad0d5eaa34334bb58b28214f280815e22abddcb1dffb4"
      width: 1920
      height: 1080
      fps: 15
      codec: "h264"
    - id: "efficientnet_b0"
      type: "model"
      source: "files"
      url: 
        - xml: "https://raw.githubusercontent.com/dlstreamer/pipeline-zoo-models/ee73878abc6fb6d864e59a5cd80016de4fc1d194/storage/efficientnet-b0_INT8/FP16-INT8/efficientnet-b0.xml"
        - bin: "https://raw.githubusercontent.com/dlstreamer/pipeline-zoo-models/ee73878abc6fb6d864e59a5cd80016de4fc1d194/storage/efficientnet-b0_INT8/FP16-INT8/efficientnet-b0.bin"
      sha256:
        - xml: "e9f959bb05ea1dc4d4735acc62e3d959fa2982b82e9608325157ba3598b5b999"
        - bin: "2ee5a5ad5a9a1a00d057e50af5da56e3bf09f633f66e9f77b9a1915ab862c536"
      precision: "int8"  # exported model precision metadata
      format: "openvino"
    # File assets
    - id: "imagenet_2012.txt"
      type: "file"
      url: "https://raw.githubusercontent.com/open-edge-platform/edge-ai-libraries/3d2c76dcbc5b0f4aa0ac11d77873427c4c86fb22/libraries/dl-streamer/samples/labels/imagenet_2012.txt"
      sha256: "acf75ef0abe89694b19056e0796401068b459c457baa30335f240c7692857355"
      path: "./labels/imagenet_2012.txt"
    - id: "preproc-aspect-ratio.json"
      type: "file"
      url: "https://raw.githubusercontent.com/open-edge-platform/edge-ai-libraries/3d2c76dcbc5b0f4aa0ac11d77873427c4c86fb22/libraries/dl-streamer/samples/gstreamer/model_proc/public/preproc-aspect-ratio.json"
      sha256: "824db3e19e1e0a71caba8370606413b2bcd0d9339fb4c5b9535d4c3f2091095a"
      path: "./labels/preproc-aspect-ratio.json"
  target_fps: 14.95
  consecutive_timeout_threshold: 2 
  pipeline: |
    filesrc location=./videos/6891009-apple_1080p15.mp4
      ! ${DECODE_ELEMENTS}
      ! queue
      ! gvadetect batch-size=${BATCH_SIZE} model-instance-id=detection model=./models/yolo11n/int8/dynamic_half/yolo11n.xml 
          threshold=0.5
          device=${DEVICE_ID}
          ${INFERENCE_ELEMENTS}
      ! queue
      ! gvatrack tracking-type=zero-term-imageless
      ! queue 
      ! gvaclassify batch-size=${BATCH_SIZE} model-instance-id=classifier
          labels=./labels/imagenet_2012.txt
          model=./models/efficientnet_b0/int8/efficientnet-b0.xml
          model-proc=./labels/preproc-aspect-ratio.json
          device=${DEVICE_ID}
          ${INFERENCE_ELEMENTS}
          reclassify-interval=1
      ! queue
  pipeline_params:
    DECODE_ELEMENTS:
      cpu: "qtdemux ! h264parse ! avdec_h264 ! video/x-raw"
      gpu_integrated: "qtdemux ! h264parse ! vah264dec ! vapostproc ! capsfilter caps='video/x-raw(memory:VAMemory)'"
      gpu_discrete: "qtdemux ! h264parse ! varenderD{RENDER_DEVICE_NUM}h264dec ! capsfilter caps='video/x-raw(memory:VAMemory)'"
      gpu_discrete_primary: "qtdemux ! h264parse ! vah264dec ! capsfilter caps='video/x-raw(memory:VAMemory)'"
      npu: "qtdemux ! h264parse ! vah264dec ! capsfilter caps='video/x-raw(memory:VAMemory)'"
    INFERENCE_ELEMENTS:
      cpu: "pre-process-backend={PRE_PROCESS_BACKEND} ie-config=CPU_THROUGHPUT_STREAMS=2 nireq=2"
      gpu_integrated: "pre-process-backend={PRE_PROCESS_BACKEND} ie-config=GPU_THROUGHPUT_STREAMS=2 nireq=2 "
      gpu_discrete: "pre-process-backend={PRE_PROCESS_BACKEND} ie-config=GPU_THROUGHPUT_STREAMS=2 nireq=2 "
      gpu_discrete_primary: "pre-process-backend={PRE_PROCESS_BACKEND} ie-config=GPU_THROUGHPUT_STREAMS=2 nireq=2 "
      npu: "pre-process-backend={PRE_PROCESS_BACKEND} nireq=4"
    PRE_PROCESS_BACKEND:
      cpu: "opencv"
      gpu_integrated: "va-surface-sharing"
      gpu_discrete: "va-surface-sharing"
      gpu_discrete_primary: "va-surface-sharing"
      npu: "opencv"
    VIDEO_RAW_TYPE:
      default: "'video/x-raw(memory:VAMemory)'"
      overrides:
        FULL_DEVICE_NAME:
          "Intel(R) Unsupported video type": "'video/x-raw'"
    BATCH_SIZE:
      cpu: "8"
      gpu_integrated: "8"
      gpu_discrete: "8"
      gpu_discrete_primary: "8"
      npu: "1"
    SINK_ELEMENT:
      default: "fakesink sync=false async=false"
    FPSCOUNTER_PROPS:
      default: ""    

suites:
  - name: "ai"
    sub_suites:
      - name: "gen"
        tests:
          test_text_generation:
            params:
              # Entry
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [cpu, igpu]
                tiers:
                  - entry
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Mainstream
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [cpu, igpu]
                tiers:
                  - mainstream
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Efficiency Optimized
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-7B INT4"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
                model_precision: "int4"
                devices: [cpu, igpu, npu]
                tiers:
                  - efficiency_optimized
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                  - throughput_npu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_npu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Scalable Performance
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (CPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [cpu]
                tiers:
                  - scalable_performance
                kpi_refs:
                  - throughput_cpu
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Scalable AI Graphics Media
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (Hetero dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_10gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_10gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_24gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (Hetero dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_24gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_52gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_52gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true


      - name: "vision"
        tests:
          test_dlstreamer:
            params:
              # Entry
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - entry
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 2
                      enabled: true

              # Mainstream
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - mainstream
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 3
                      enabled: true

              # Efficiency Optimized
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - efficiency_optimized
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 4
                      enabled: true

              # Scalable Performance
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - scalable_performance
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 11
                      enabled: true

              # Scalable AI Graphic Media
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  # dGPU based specific tiers
                  - scalable_ai_graphics_media
                  - scalable_ai_graphics_media_10gb
                  - scalable_ai_graphics_media_24gb
                  - scalable_ai_graphics_media_52gb
                  - scalable_ai_graphics_media_hetero
                  - scalable_ai_graphics_media_hetero_10gb
                  - scalable_ai_graphics_media_hetero_24gb
                  - scalable_ai_graphics_media_hetero_52gb
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 9
                      enabled: true
