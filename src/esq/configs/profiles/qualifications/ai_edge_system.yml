# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

name: "profile.qualification.ai-edge-system"
description: "AI Edge System qualification"
version: "1.0.0"
params:
  labels:
    profile_display_name: "AI Edge System"
    group: "ai-edge-system"
    type: "qualification"
    display_reference: true
    kpi_enabled: true
  tiers:
    - entry
    - mainstream
    - efficiency_optimized
    # Xeon based specific tier
    - scalable_performance
    # dGPU based specific tiers
    - scalable_ai_graphics_media
    - scalable_ai_graphics_media_10gb
    - scalable_ai_graphics_media_24gb
    - scalable_ai_graphics_media_52gb
    - scalable_ai_graphics_media_hetero
    - scalable_ai_graphics_media_hetero_10gb
    - scalable_ai_graphics_media_hetero_24gb
    - scalable_ai_graphics_media_hetero_52gb
  requirements:
    memory_min_gb: 8.0
    os_type:
      - "linux"
    docker_required: true
  # Vision AI global params
  videos:
    - name: "1192116-hd_1920_1080_15fps_30s.mp4"
      url: "https://videos.pexels.com/video-files/1192116/1192116-hd_1920_1080_30fps.mp4"
      sha256: "65d836330fda9cfe6aa7a6bb4b2a81df4897325133da096b275e40b359e2d4ea"
      fps: 15
      duration: 30
  models:
    - id: "yolo11n"
      source: "ultralytics"
      precision: "fp16"
      format: "pt"
  pipeline: |
    filesrc location=./videos/1192116-hd_1920_1080_15fps_30s.mp4
      ! ${DECODE_ELEMENTS}
      ! gvadetect model=./models/yolo11n/fp16/yolo11n.xml device=${DEVICE_ID} ${INFERENCE_ELEMENTS} batch-size=1
      ! queue
  pipeline_params:
    DECODE_ELEMENTS:
      cpu: "parsebin ! avdec_h264 ! 'video/x-raw'"
      gpu_integrated: "parsebin ! vah264dec ! vapostproc ! 'video/x-raw(memory:VAMemory)'"
      gpu_discrete: "parsebin ! varenderD{RENDER_DEVICE_NUM}h264dec ! {VIDEO_RAW_TYPE}"
      npu: "parsebin ! vah264dec ! 'video/x-raw(memory:VAMemory)'"
    INFERENCE_ELEMENTS:
      cpu: "pre-process-backend={PRE_PROCESS_BACKEND}"
      gpu_integrated: "pre-process-backend={PRE_PROCESS_BACKEND} model-instance-id=inst0"
      gpu_discrete: "pre-process-backend={PRE_PROCESS_BACKEND}"
      npu: "pre-process-backend={PRE_PROCESS_BACKEND}"
    PRE_PROCESS_BACKEND:
      cpu: "ie"
      gpu_integrated: "va-surface-sharing"
      gpu_discrete: "va-surface-sharing"
      npu: "va"
    VIDEO_RAW_TYPE:
      default: "'video/x-raw(memory:VAMemory)'"
      overrides:
        FULL_DEVICE_NAME:
          "Intel(R) Unsupported video type": "'video/x-raw'"

suites:
  - name: "ai"
    sub_suites:
      - name: "gen"
        tests:
          test_text_generation:
            params:
              # Entry
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [cpu, igpu]
                tiers:
                  - entry
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Mainstream
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [cpu, igpu]
                tiers:
                  - mainstream
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Efficiency Optimized
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-7B INT4"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
                model_precision: "int4"
                devices: [cpu, igpu, npu]
                tiers:
                  - efficiency_optimized
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                  - throughput_npu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_npu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Scalable Performance
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (CPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [cpu]
                tiers:
                  - scalable_performance
                kpi_refs:
                  - throughput_cpu
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Scalable AI Graphics Media
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (Hetero dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_10gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_10gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_24gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (Hetero dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_24gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_52gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_52gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true


      - name: "vision"
        tests:
          test_dlstreamer:
            params:
              # Entry
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Benchmark - multi-stream 1080p15 H.264 gvadetect YOLO11n FP16"
                devices: [cpu, igpu]
                tiers:
                  - entry
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 2
                      enabled: true

              # Mainstream
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Benchmark - multi-stream 1080p15 H.264 gvadetect YOLO11n FP16"
                devices: [cpu, igpu]
                tiers:
                  - mainstream
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 7
                      enabled: true

              # Efficiency Optimized
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Benchmark - multi-stream 1080p15 H.264 gvadetect YOLO11n FP16"
                devices: [cpu, igpu, npu]
                tiers:
                  - efficiency_optimized
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 10
                      enabled: true

              # Scalable Performance
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Benchmark - multi-stream 1080p15 H.264 gvadetect YOLO11n FP16"
                devices: [cpu]
                tiers:
                  - scalable_performance
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 60
                      enabled: true

              # Scalable AI Graphic Media
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Benchmark - multi-stream 1080p15 H.264 gvadetect YOLO11n FP16"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  # dGPU based specific tiers
                  - scalable_ai_graphics_media
                  - scalable_ai_graphics_media_10gb
                  - scalable_ai_graphics_media_24gb
                  - scalable_ai_graphics_media_52gb
                  - scalable_ai_graphics_media_hetero
                  - scalable_ai_graphics_media_hetero_10gb
                  - scalable_ai_graphics_media_hetero_24gb
                  - scalable_ai_graphics_media_hetero_52gb
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 30
                      enabled: true
