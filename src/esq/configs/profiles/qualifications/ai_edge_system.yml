# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

name: "profile.qualification.ai-edge-system"
description: "AI Edge System qualification"
version: "1.0.0"
params:
  labels:
    profile_display_name: "AI Edge System"
    group: "ai-edge-system"
    type: "qualification"
    display_reference: true
    kpi_enabled: true
  tiers:
    - entry
    - mainstream
    - efficiency_optimized
    # Xeon based specific tier
    - scalable_performance
    # dGPU based specific tiers
    - scalable_ai_graphics_media
    - scalable_ai_graphics_media_10gb
    - scalable_ai_graphics_media_24gb
    - scalable_ai_graphics_media_52gb
    - scalable_ai_graphics_media_hetero
    - scalable_ai_graphics_media_hetero_10gb
    - scalable_ai_graphics_media_hetero_24gb
    - scalable_ai_graphics_media_hetero_52gb
  requirements:
    memory_min_gb: 8.0
    os_type:
      - "linux"
    docker_required: true
  # Verified reference data for Gen AI and Vision AI tests
  # This data will be filtered by CPU generation and attached to test results
  verified_reference_data:
    gen_ai:
      # Column mappings for CSV headers (human-readable labels)
      columns:
        device_sku: "Device SKU"
        type: "Type"
        model: "AI Model"
        precision: "Precision"
        batch_size: "Batch Size"
        throughput_tokens_per_sec: "Throughput (Tokens/s)"
        first_token_latency_ms: "1st Token Latency (ms)"
        perf_per_watt: "Perf/W"
      # Reference data entries
      data:
        - device_sku: "Intel Core i9 273PQE (12 Cores)"
          type: "CPU"
          model: "DeepSeek-R1-Distill-Qwen-7B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 14
          first_token_latency_ms: 4589
          perf_per_watt: "N/A"
        - device_sku: "Intel Core Ultra 7 255H"
          type: "iGPU"
          model: "DeepSeek-R1-Distill-Qwen-7B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 15.6
          first_token_latency_ms: 528
          perf_per_watt: 0.75
        - device_sku: "Intel Core Ultra 7 255H"
          type: "NPU"
          model: "Phi3-mini-4k-instruct"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 15
          first_token_latency_ms: 2620
          perf_per_watt: 1.04
        - device_sku: "Intel Core Ultra Series 3 X7 358H"
          type: "iGPU"
          model: "DeepSeek-R1-Distill-Qwen-7B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 26
          first_token_latency_ms: 200
          perf_per_watt: 0.59
        - device_sku: "Intel Core Ultra Series 3 X7 358H"
          type: "NPU"
          model: "DeepSeek-R1-Distill-Qwen-7B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 21
          first_token_latency_ms: 10306
          perf_per_watt: 1.96
        - device_sku: "Intel Xeon 6730P (32 Cores at 2.5GHz)"
          type: "CPU"
          model: "Qwen3-32B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 10.39
          first_token_latency_ms: 4473
          perf_per_watt: 0.03
        - device_sku: "Intel Xeon 6761P (64 Cores at 2.5GHz)"
          type: "CPU"
          model: "Qwen3-32B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 11.96
          first_token_latency_ms: 2706
          perf_per_watt: 0.04
        - device_sku: "Intel Xeon 678X (48 Cores at 2.4GHz)"
          type: "CPU"
          model: "DeepSeek-R1-Distill-Qwen-14B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 19.5
          first_token_latency_ms: 1479.39
          perf_per_watt: "N/A"
        - device_sku: "Intel ARC B50"
          type: "dGPU"
          model: "DeepSeek-R1-Distill-Qwen-14B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 25
          first_token_latency_ms: 418
          perf_per_watt: "N/A"
        - device_sku: "Intel ARC B60"
          type: "dGPU"
          model: "DeepSeek-R1-Distill-Qwen-32B"
          precision: "INT4"
          batch_size: 1
          throughput_tokens_per_sec: 44
          first_token_latency_ms: 237.7
          perf_per_watt: "N/A"
    vision_ai:
      # Column mappings for CSV headers (human-readable labels)
      columns:
        device_sku: "Device SKU"
        type: "Type"
        precision: "Precision"
        batch_size: "Batch Size"
        no_of_streams: "No. of Streams"
        power_per_stream: "Power/Stream"
      # Reference data entries
      data:
        - device_sku: "Intel Core Ultra 7 255H"
          type: "CPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 8
          power_per_stream: 49.64
        - device_sku: "Intel Core Ultra 7 255H"
          type: "iGPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 19
          power_per_stream: 27.04
        - device_sku: "Intel Core Ultra 7 255H"
          type: "NPU"
          precision: "INT8"
          batch_size: 1
          no_of_streams: 10
          power_per_stream: 18.52
        - device_sku: "Intel Core Ultra Series 3 X7 358H"
          type: "CPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 8
          power_per_stream: 0.14
        - device_sku: "Intel Core Ultra Series 3 X7 358H"
          type: "iGPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 44
          power_per_stream: 1.18
        - device_sku: "Intel Xeon 6730P (32 Cores at 2.5GHz)"
          type: "CPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 20
          power_per_stream: "N/A"
        - device_sku: "Intel Xeon 6761P (64 Cores at 2.5GHz)"
          type: "CPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 31
          power_per_stream: "N/A"
        - device_sku: "Intel ARC B50"
          type: "dGPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 24
          power_per_stream: "N/A"
        - device_sku: "Intel ARC B60"
          type: "dGPU"
          precision: "INT8"
          batch_size: 8
          no_of_streams: 36
          power_per_stream: "N/A"
  # Vision AI global params
  assets:
    - id: "yolo11n"
      type: "model"
      source: "ultralytics"
      precision: "int8"
      format: "pt"
      export_args:
        dynamic: true
        half: true
    - id: "video_6891009"
      type: "video"
      name: "6891009-apple_1080p15.mp4"
      url: "https://www.pexels.com/download/video/6891009"
      sha256: "b30010389562c03a15dad0d5eaa34334bb58b28214f280815e22abddcb1dffb4"
      width: 1920
      height: 1080
      fps: 15
      codec: "h264"
    - id: "efficientnet_b0"
      type: "model"
      source: "files"
      url: 
        - xml: "https://raw.githubusercontent.com/dlstreamer/pipeline-zoo-models/ee73878abc6fb6d864e59a5cd80016de4fc1d194/storage/efficientnet-b0_INT8/FP16-INT8/efficientnet-b0.xml"
        - bin: "https://raw.githubusercontent.com/dlstreamer/pipeline-zoo-models/ee73878abc6fb6d864e59a5cd80016de4fc1d194/storage/efficientnet-b0_INT8/FP16-INT8/efficientnet-b0.bin"
      sha256:
        - xml: "e9f959bb05ea1dc4d4735acc62e3d959fa2982b82e9608325157ba3598b5b999"
        - bin: "2ee5a5ad5a9a1a00d057e50af5da56e3bf09f633f66e9f77b9a1915ab862c536"
      precision: "int8"  # exported model precision metadata
      format: "openvino"
    # File assets
    - id: "imagenet_2012.txt"
      type: "file"
      url: "https://raw.githubusercontent.com/open-edge-platform/edge-ai-libraries/3d2c76dcbc5b0f4aa0ac11d77873427c4c86fb22/libraries/dl-streamer/samples/labels/imagenet_2012.txt"
      sha256: "acf75ef0abe89694b19056e0796401068b459c457baa30335f240c7692857355"
      path: "./labels/imagenet_2012.txt"
    - id: "preproc-aspect-ratio.json"
      type: "file"
      url: "https://raw.githubusercontent.com/open-edge-platform/edge-ai-libraries/3d2c76dcbc5b0f4aa0ac11d77873427c4c86fb22/libraries/dl-streamer/samples/gstreamer/model_proc/public/preproc-aspect-ratio.json"
      sha256: "824db3e19e1e0a71caba8370606413b2bcd0d9339fb4c5b9535d4c3f2091095a"
      path: "./labels/preproc-aspect-ratio.json"
  target_fps: 14.95
  consecutive_timeout_threshold: 4 
  pipeline: |
    filesrc location=./videos/6891009-apple_1080p15.mp4
      ! ${DECODE_ELEMENTS}
      ! queue
      ! gvadetect batch-size=${BATCH_SIZE} model-instance-id=detection model=./models/yolo11n/int8/dynamic_half/yolo11n.xml 
          threshold=0.5
          device=${DEVICE_ID}
          ${INFERENCE_ELEMENTS}
      ! queue
      ! gvatrack tracking-type=zero-term-imageless
      ! queue 
      ! gvaclassify batch-size=${BATCH_SIZE} model-instance-id=classifier
          labels=./labels/imagenet_2012.txt
          model=./models/efficientnet_b0/int8/efficientnet-b0.xml
          model-proc=./labels/preproc-aspect-ratio.json
          device=${DEVICE_ID}
          ${INFERENCE_ELEMENTS}
          reclassify-interval=1
      ! queue
  pipeline_params:
    DECODE_ELEMENTS:
      default: "qtdemux ! h264parse ! avdec_h264 ! video/x-raw"
      cpu: "qtdemux ! h264parse ! avdec_h264 ! video/x-raw"
      npu: "qtdemux ! h264parse ! vah264dec ! capsfilter caps='video/x-raw(memory:VAMemory)'"
      igpu: "qtdemux ! h264parse ! va${RENDER_DEVICE}h264dec ! va${RENDER_DEVICE}postproc ! capsfilter caps='video/x-raw(memory:VAMemory)'"
      dgpu: "qtdemux ! h264parse ! va${RENDER_DEVICE}h264dec ! va${RENDER_DEVICE}postproc ! capsfilter caps='video/x-raw(memory:VAMemory)'"
    INFERENCE_ELEMENTS:
      default: "pre-process-backend=va-surface-sharing ie-config=GPU_THROUGHPUT_STREAMS=2 nireq=2"
      cpu: "pre-process-backend=opencv ie-config=CPU_THROUGHPUT_STREAMS=2 nireq=2"
      npu: "pre-process-backend=opencv nireq=4"
    BATCH_SIZE:
      default: "8"
      npu: "1"
    SINK_ELEMENT:
      default: "fakesink sync=false async=false"
    FPSCOUNTER_PROPS:
      default: ""

suites:
  - name: "ai"
    sub_suites:
      - name: "gen"
        params:
          venv:
            enabled: false
        tests:
          test_text_generation:
            params:
              # Entry
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [cpu, igpu]
                tiers:
                  - entry
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Mainstream
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [cpu, igpu]
                tiers:
                  - mainstream
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Efficiency Optimized
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-7B INT4"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
                model_precision: "int4"
                devices: [cpu, igpu, npu]
                tiers:
                  - efficiency_optimized
                kpi_refs:
                  - throughput_cpu
                  - throughput_igpu
                  - throughput_npu
                kpi_validation_mode: "any"
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_igpu:
                    validation:
                      reference: 10.0
                      enabled: true
                  throughput_npu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Scalable Performance
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (CPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [cpu]
                tiers:
                  - scalable_performance
                kpi_refs:
                  - throughput_cpu
                kpi_override:
                  throughput_cpu:
                    validation:
                      reference: 10.0
                      enabled: true

              # Scalable AI Graphics Media
              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (Hetero dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_10gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_10gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [dgpu]
                tiers:
                  - scalable_ai_graphics_media_24gb
                  - scalable_ai_graphics_media_52gb
                kpi_refs:
                  - throughput_dgpu
                kpi_override:
                  throughput_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true

              - test_id: "AES-GEN-001"
                display_name: "Gen AI LLM Serving Benchmark - Qwen3-32B INT4 (Hetero dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                tiers:
                  - scalable_ai_graphics_media_hetero_24gb
                  - scalable_ai_graphics_media_hetero_52gb
                kpi_refs:
                  - throughput_hetero_dgpu
                kpi_override:
                  throughput_hetero_dgpu:
                    validation:
                      reference: 10.0
                      enabled: true


      - name: "vision"
        params:
          venv:
            enabled: false
            requirements_file: "src/dlstreamer/requirements.txt"
            python_version: null
            timeout: 7200
        tests:
          test_dlstreamer:
            params:
              # Entry
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - entry
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 4
                      enabled: true

              # Mainstream
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - mainstream
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 8
                      enabled: true

              # Efficiency Optimized
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - efficiency_optimized
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 25
                      enabled: true

              # Scalable Performance
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  - scalable_performance
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 10
                      enabled: true

              # Scalable AI Graphic Media
              - test_id: "AES-VSN-001"
                display_name: "Vision AI Analysis - multi-stream 1080p15 H.264 gvadetect YOLO11n INT8 gvatrack gvaclassify EfficientNet-B0 INT8"
                devices: [cpu, igpu, dgpu, npu]
                tiers:
                  # dGPU based specific tiers
                  - scalable_ai_graphics_media
                  - scalable_ai_graphics_media_10gb
                  - scalable_ai_graphics_media_24gb
                  - scalable_ai_graphics_media_52gb
                  - scalable_ai_graphics_media_hetero
                  - scalable_ai_graphics_media_hetero_10gb
                  - scalable_ai_graphics_media_hetero_24gb
                  - scalable_ai_graphics_media_hetero_52gb
                kpi_refs:
                  - streams_max
                kpi_override:
                  streams_max:
                    validation:
                      reference: 40
                      enabled: true
