# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

name: "profile.suite.ai.gen"
description: "Gen AI suite profile"
version: "1.0.0"
params:
  labels:
    profile_display_name: "Gen AI"
    group: "ai.gen"
    type: "suite"
    display_status: false
  requirements:
    # Hardware requirements
    cpu_min_cores: 2
    memory_min_gb: 5.0
    storage_min_gb: 10.0
    # Software requirements
    os_type:
      - "linux"
    docker_required: true

suites:
  - name: "ai"
    sub_suites:
      - name: "gen"
      
        tests:
          test_text_generation:
            params:
              - test_id: "GEN-LLM-001"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4 (CPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [cpu]
                requirements:
                  memory_min_gb: 8.0

              - test_id: "GEN-LLM-002"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4 (iGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [igpu]
                requirements:
                  igpu_required: true
                  memory_min_gb: 8.0

              - test_id: "GEN-LLM-003"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [dgpu]
                requirements:
                  dgpu_required: true
                  dgpu_min_vram_gb: 2.0

              - test_id: "GEN-LLM-004"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                requirements:
                  dgpu_min_devices: 2
                  dgpu_min_vram_gb: 2.0

              - test_id: "GEN-LLM-005"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-1.5B INT4 (NPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
                model_precision: "int4"
                devices: [npu]
                requirements:
                  npu_required: true
                  memory_min_gb: 8.0

              - test_id: "GEN-LLM-006"
                display_name: "LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (CPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [cpu]
                requirements:
                  memory_min_gb: 9.0

              - test_id: "GEN-LLM-007"
                display_name: "LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (iGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [igpu]
                requirements:
                  igpu_required: true
                  memory_min_gb: 9.0

              - test_id: "GEN-LLM-008"
                display_name: "LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [dgpu]
                requirements:
                  dgpu_required: true
                  dgpu_min_vram_gb: 3.0

              - test_id: "GEN-LLM-009"
                display_name: "LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (Hetero dGPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [hetero-dgpu]
                requirements:
                  dgpu_min_devices: 2
                  dgpu_min_vram_gb: 3.0

              - test_id: "GEN-LLM-010"
                display_name: "LLM Serving Benchmark - Phi-4-mini-reasoning 3.8B INT4 (NPU)"
                model_id: "microsoft/Phi-4-mini-reasoning"
                model_precision: "int4"
                devices: [npu]
                requirements:
                  npu_required: true
                  memory_min_gb: 9.0

              - test_id: "GEN-LLM-011"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (CPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [cpu]
                requirements:
                  memory_min_gb: 16.0

              - test_id: "GEN-LLM-012"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (iGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [igpu]
                requirements:
                  igpu_required: true
                  memory_min_gb: 16.0

              - test_id: "GEN-LLM-013"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [dgpu]
                requirements:
                  dgpu_required: true
                  dgpu_min_vram_gb: 10.0

              - test_id: "GEN-LLM-014"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                requirements:
                  dgpu_min_devices: 2
                  dgpu_min_vram_gb: 10.0

              - test_id: "GEN-LLM-015"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Qwen-14B INT4 (NPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                model_precision: "int4"
                devices: [npu]
                requirements:
                  npu_required: true
                  memory_min_gb: 16.0

              - test_id: "GEN-LLM-016"
                display_name: "LLM Serving Benchmark - Qwen3-32B INT4 (CPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [cpu]
                requirements:
                  memory_min_gb: 30.0

              - test_id: "GEN-LLM-017"
                display_name: "LLM Serving Benchmark - Qwen3-32B INT4 (iGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [igpu]
                requirements:
                  igpu_required: true
                  memory_min_gb: 30.0

              - test_id: "GEN-LLM-018"
                display_name: "LLM Serving Benchmark - Qwen3-32B INT4 (dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [dgpu]
                requirements:
                  dgpu_required: true
                  dgpu_min_vram_gb: 24.0

              - test_id: "GEN-LLM-019"
                display_name: "LLM Serving Benchmark - Qwen3-32B INT4 (Hetero dGPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                requirements:
                  dgpu_min_devices: 2
                  dgpu_min_vram_gb: 24.0

              - test_id: "GEN-LLM-020"
                display_name: "LLM Serving Benchmark - Qwen3-32B INT4 (NPU)"
                model_id: "Qwen/Qwen3-32B"
                model_precision: "int4"
                devices: [npu]
                requirements:
                  npu_required: true
                  memory_min_gb: 30.0

              - test_id: "GEN-LLM-021"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (CPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [cpu]
                requirements:
                  memory_min_gb: 58.0

              - test_id: "GEN-LLM-022"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (iGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [igpu]
                requirements:
                  igpu_required: true
                  memory_min_gb: 58.0

              - test_id: "GEN-LLM-023"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [dgpu]
                requirements:
                  dgpu_required: true
                  dgpu_min_vram_gb: 52.5

              - test_id: "GEN-LLM-024"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (Hetero dGPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [hetero-dgpu]
                requirements:
                  dgpu_min_devices: 2
                  dgpu_min_vram_gb: 52.5

              - test_id: "GEN-LLM-025"
                display_name: "LLM Serving Benchmark - DeepSeek-R1-Distill-Llama-70B INT4 (NPU)"
                model_id: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
                model_precision: "int4"
                devices: [npu]
                requirements:
                  npu_required: true
                  memory_min_gb: 58.0
